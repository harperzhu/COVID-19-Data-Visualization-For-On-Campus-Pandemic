head(groupRes)
table(groupRes$XORlev2)
### Major takeaway
groupRes$method <- factor(groupRes$method, ordered=TRUE, levels=c("splitting", "condition", "ctree"))
groupRes$XORlev2 <- paste("\u03B1=", groupRes$XORLev)
ggplot(data=groupRes , aes(x=beta, y=propCorrect, col=interaction(method, "detect"), lty=interaction(method, "detect"))) + geom_smooth(se=F)+
geom_smooth(aes(x=beta,y=propCorrectReject, col=interaction(method,"reject"), lty=interaction(method,"reject")),
se=F)+
ylab("Proportion of True Splits Detected/Rejected")+xlab(expression(beta))+
scale_color_manual(name = "Method", values = c("#00BFC4", "#00BFC4", "#F8766D", "#F8766D", "black", "black"),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection")) +
scale_linetype_manual(name = "Method", values = c(1,3,1,3,1,3),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection"
))+facet_grid(cols = vars(XORlev2),
rows = vars(truesplitlev)) + theme_bw()
res <- read.csv("~/ActuallyRealSims/Full_Rand_Comps_FIX_12-06.csv", header=FALSE,sep=" ")
names(res)<- c("cp", "seed", "depth", "beta", "method", "pval", "truesig",
"n1", "n2", "samplesig", "bestRand", "whichSplit","XORlev", "best", "NA")
res <- res %>% filter(!is.na(pval))
res <- res %>% filter(XORlev !=3, XORlev >= 0.5)
res2 <- res %>% group_by(cp, method, seed,XORlev,beta, depth, pval, truesig, n1, n2, samplesig) %>%
summarize(bestRand = max(bestRand), whichSplit = whichSplit[which.max(bestRand)])
res2 <- res2 %>% mutate(whichSplitLev = ifelse(whichSplit >=3,3,whichSplit))
res2 <- res2 %>% mutate(truesplitlev = ifelse(whichSplit >=3, 3, whichSplit))
res2 <- res2 %>%
mutate(
correct = as.numeric(bestRand > 0.75),
correctreject = as.numeric(bestRand > 0.75 & pval < 0.05)
)
#### HOW MANY TRUE TREES WERE MADE FOR EACH BETA
ntree <-  NROW((res %>% filter(depth==1,method=="condition",XORlev==2,beta==10)))
groupRes <- res2 %>% group_by(method, XORlev, truesplitlev, beta) %>% summarize(
numcorrect = sum(correct),
numcorrectreject = sum(correctreject)
) %>%
mutate(propCorrect = ifelse(truesplitlev < 3, numcorrect/ntree, numcorrect/(2*ntree)),
propCorrectReject= ifelse(truesplitlev < 3, numcorrectreject/ntree, numcorrectreject/(2*ntree))
) %>%
mutate(
beta=as.numeric(beta),
propCorrect=as.numeric(propCorrect),
propCorrectReject=as.numeric(propCorrectReject)
) %>%
mutate(truesplitlev = paste("Level ", truesplitlev))
### Major takeaway
groupRes$method <- factor(groupRes$method, ordered=TRUE, levels=c("splitting", "condition", "ctree"))
groupRes$XORlev2 <- paste("\u03B1=", groupRes$XORLev)
ggplot(data=groupRes , aes(x=beta, y=propCorrect, col=interaction(method, "detect"), lty=interaction(method, "detect"))) + geom_smooth(se=F)+
geom_smooth(aes(x=beta,y=propCorrectReject, col=interaction(method,"reject"), lty=interaction(method,"reject")),
se=F)+
ylab("Proportion of True Splits Detected/Rejected")+xlab(expression(beta))+
scale_color_manual(name = "Method", values = c("#00BFC4", "#00BFC4", "#F8766D", "#F8766D", "black", "black"),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection")) +
scale_linetype_manual(name = "Method", values = c(1,3,1,3,1,3),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection"
))+facet_grid(cols = vars(XORlev2),
rows = vars(truesplitlev)) + theme_bw()
head(groupRes)
groupRes$XORlev2 <- paste0("\u03B1=", groupRes$XORLev)
res <- read.csv("~/ActuallyRealSims/Full_Rand_Comps_FIX_12-06.csv", header=FALSE,sep=" ")
names(res)<- c("cp", "seed", "depth", "beta", "method", "pval", "truesig",
"n1", "n2", "samplesig", "bestRand", "whichSplit","XORlev", "best", "NA")
res <- res %>% filter(!is.na(pval))
res <- res %>% filter(XORlev !=3, XORlev >= 0.5)
res2 <- res %>% group_by(cp, method, seed,XORlev,beta, depth, pval, truesig, n1, n2, samplesig) %>%
summarize(bestRand = max(bestRand), whichSplit = whichSplit[which.max(bestRand)])
res2 <- res2 %>% mutate(whichSplitLev = ifelse(whichSplit >=3,3,whichSplit))
res2 <- res2 %>% mutate(truesplitlev = ifelse(whichSplit >=3, 3, whichSplit))
res2 <- res2 %>%
mutate(
correct = as.numeric(bestRand > 0.75),
correctreject = as.numeric(bestRand > 0.75 & pval < 0.05)
)
#### HOW MANY TRUE TREES WERE MADE FOR EACH BETA
ntree <-  NROW((res %>% filter(depth==1,method=="condition",XORlev==2,beta==10)))
groupRes <- res2 %>% group_by(method, XORlev2, truesplitlev, beta) %>% summarize(
numcorrect = sum(correct),
numcorrectreject = sum(correctreject)
) %>%
mutate(propCorrect = ifelse(truesplitlev < 3, numcorrect/ntree, numcorrect/(2*ntree)),
propCorrectReject= ifelse(truesplitlev < 3, numcorrectreject/ntree, numcorrectreject/(2*ntree))
) %>%
mutate(
beta=as.numeric(beta),
propCorrect=as.numeric(propCorrect),
propCorrectReject=as.numeric(propCorrectReject)
) %>%
mutate(truesplitlev = paste("Level ", truesplitlev))
res2 <- res2 %>% mutate(truesplitlev = ifelse(whichSplit >=3, 3, whichSplit))
res2 <- res2 %>%
mutate(
correct = as.numeric(bestRand > 0.75),
correctreject = as.numeric(bestRand > 0.75 & pval < 0.05)
)
#### HOW MANY TRUE TREES WERE MADE FOR EACH BETA
ntree <-  NROW((res %>% filter(depth==1,method=="condition",XORlev==2,beta==10)))
groupRes <- res2 %>% group_by(method, XORlev, truesplitlev, beta) %>% summarize(
numcorrect = sum(correct),
numcorrectreject = sum(correctreject)
) %>%
mutate(propCorrect = ifelse(truesplitlev < 3, numcorrect/ntree, numcorrect/(2*ntree)),
propCorrectReject= ifelse(truesplitlev < 3, numcorrectreject/ntree, numcorrectreject/(2*ntree))
) %>%
mutate(
beta=as.numeric(beta),
propCorrect=as.numeric(propCorrect),
propCorrectReject=as.numeric(propCorrectReject)
) %>%
mutate(truesplitlev = paste("Level ", truesplitlev))
### Major takeaway
groupRes$method <- factor(groupRes$method, ordered=TRUE, levels=c("splitting", "condition", "ctree"))
groupRes$XORlev2 <- paste0("\u03B1=", groupRes$XORlev)
ggplot(data=groupRes , aes(x=beta, y=propCorrect, col=interaction(method, "detect"), lty=interaction(method, "detect"))) + geom_smooth(se=F)+
geom_smooth(aes(x=beta,y=propCorrectReject, col=interaction(method,"reject"), lty=interaction(method,"reject")),
se=F)+
ylab("Proportion of True Splits Detected/Rejected")+xlab(expression(beta))+
scale_color_manual(name = "Method", values = c("#00BFC4", "#00BFC4", "#F8766D", "#F8766D", "black", "black"),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection")) +
scale_linetype_manual(name = "Method", values = c(1,3,1,3,1,3),
labels=c("tree-values, detection",
"tree-values, rejection",
"CTree, detection",
"CTree, rejection",
"Sample Splitting, detection",
"Sample Splitting", "rejection"
))+facet_grid(cols = vars(XORlev2),
rows = vars(truesplitlev)) + theme_bw()
groupRes$XORlev2 <- paste0(sprintf("\u03B1="), groupRes$XORlev)
head(groupRes)
head(groupRes$XORlev2)
res <- read.csv("nonnull_res_12-04-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
table(is.na(res$lower))
knitr::kable(res %>% filter(type=="child", XORLev %in% c(0.25, 1,2)) %>% group_by(XORLev, type, depth) %>%
summarize("Median Width, Sample Splitting" = median(length[method=="splitting"], na.rm=TRUE),
"Median Width, Tree-Values" = median(length[method=="Tree-Values"], na.rm=TRUE)))
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
res <- read.csv("nonnull_res_12-04-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
res <- res %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,
length = upper - lower, invalid = n1*n2==0)
res <- res %>% filter(XORLev != 0, XORLev !=3)
#res2 <- read.csv("nonnull_res_permutation_12-06-20.csv", header=FALSE, sep=" #")
#names(res2) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", #"pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", #"sizeS", "sizeNum")
#res2 <- res2 %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,length = upper - lower, invalid = n1*n2==0)
#res2 <- res2 %>% filter(XORLev != 0, XORLev !=3, method=="Tree-Values")
#res2 <- res2 %>% mutate(method = paste0(method, " (S_reg)"))
#res <- rbind(res,res2)
knitr::kable(res %>% group_by(method, type) %>% summarize("Full Coverage" = round(mean(correctCI, na.rm=TRUE),3),
"Test Coverage" = round(mean(correctCItest, na.rm=TRUE),3), "Number of Splits" = n(),
"Number of Intervals" = sum(!is.na(length))))
knitr::kable(res %>% filter(type=="child", XORLev %in% c(0.25, 1,2)) %>% group_by(XORLev, type, depth) %>%
summarize("Median Width, Sample Splitting" = median(length[method=="splitting"], na.rm=TRUE),
"Median Width, Tree-Values" = median(length[method=="Tree-Values"], na.rm=TRUE)))
#"Median Width,  Tree-Values (S_reg)" = mean(length[method=="Tree-Values (S_reg)"], na.rm=TRUE)),digits=3)
groupRes <- res %>% filter(type=="child", depth < 4, XORLev %in% c(0.25,1,2)) %>% group_by(method, beta, XORLev, depth) %>% summarize(length=median(length,na.rm=TRUE))
groupRes <- groupRes %>% mutate(XORlev2 = paste0("a=", XORLev),
depth2 = paste0("depth =", depth))
ggplot(data=groupRes, aes(x=beta, y=length, col=method))+ geom_smooth()+facet_grid(cols=vars(XORlev2), rows=vars(depth2))+scale_y_log10()+ylab("Median Length")+xlab(expression(Beta))
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res, aes(x=beta, y=propThrow,col=XORLev)) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha))
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res, aes(x=beta, y=propThrow,col=XORLev)) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha)) + ylim(0,1)
head(res)
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res, aes(x=beta, y=propThrow,group=XORLev, col=XORLev)) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha)) + ylim(0,1)
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res, aes(x=beta, y=propThrow,group=XORLev, col=as.factor(XORLev))) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha)) + ylim(0,1)
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res, aes(x=beta, y=propThrow,group=XORLev, col=as.factor(XORLev))) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha)) + ylim(0,1)+facet_grid(cols=vars(depth))
res <- res %>% mutate(propThrow = sizeNum/(2*abs(sampsig)))
ggplot(data=res %>% filter(XORLev==2, method=="Tree-Values"), aes(x=propThrow, y=length)) + geom_smooth() + scale_y_log10() + xlab("Proportion of Information Thrown Away") + ylab("CI Length (Log Scale)")
ggplot(data=res %>%filter(XORLev != 0.25), aes(x=beta, y=propThrow,group=XORLev, col=as.factor(XORLev))) + geom_smooth() + ylab("Proportion of Information Thrown Away")+xlab(expression(beta))+labs(col=expression(alpha)) + ylim(0,1)+facet_grid(cols=vars(depth))
res <- read.csv("nonnull_res_newcomplex_12-07-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
res <- res %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,
length = upper - lower, invalid = n1*n2==0)
res <- res %>% filter(XORLev != 0, XORLev !=3)
max(res$seed)
table(res$beta)
res <- read.csv("nonnull_res_newcomplex_12-07-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
res <- res %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,
length = upper - lower, invalid = n1*n2==0)
res <- res %>% filter(XORLev != 0, XORLev !=3)
groupRes <- res %>% filter(type=="child", depth < 4, XORLev %in% c(0.25,1,2)) %>% group_by(method, beta, XORLev, depth) %>% summarize(length=median(length,na.rm=TRUE))
groupRes <- groupRes %>% mutate(XORlev2 = paste0("a=", XORLev),
depth2 = paste0("depth =", depth))
ggplot(data=groupRes, aes(x=beta, y=length, col=method))+ geom_smooth()+facet_grid(cols=vars(XORlev2), rows=vars(depth2))+scale_y_log10()+ylab("Median Length")+xlab(expression(Beta))
res <- read.csv("nonnull_res_newcomplex_12-07-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
res <- res %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,
length = upper - lower, invalid = n1*n2==0)
res <- res %>% filter(XORLev != 0, XORLev !=3)
knitr::kable(res %>% filter(type=="child", XORLev %in% c(0.25, 1,2), truesig > 0.1*beta) %>% group_by(XORLev, type, depth) %>%
summarize("Median Width, Sample Splitting" = median(length[method=="splitting"], na.rm=TRUE),
"Median Width, Tree-Values" = median(length[method=="Tree-Values"], na.rm=TRUE)))
groupRes <- res %>% filter(type=="child", depth < 4, XORLev %in% c(0.25,1,2)) %>% group_by(method, beta, XORLev, depth) %>% summarize(length=median(length,na.rm=TRUE))
groupRes <- groupRes %>% mutate(XORlev2 = paste0("a=", XORLev),
depth2 = paste0("depth =", depth))
ggplot(data=groupRes, aes(x=beta, y=length, col=method))+ geom_smooth()+facet_grid(cols=vars(XORlev2), rows=vars(depth2))+scale_y_log10()+ylab("Median Length")+xlab(expression(Beta))
NROW(rs)
NROW(res)
max(res$seed)
res <- read.csv("nonnull_res_newcomplex_12-07-20.csv", header=FALSE, sep=" ")
names(res) <- c("beta", "XORLev", "cp", "seed", "method", "type", "depth", "pval", "lower", "upper", "n1", "n2", "sampsig","truesig", "truesigtest", "sizeS", "sizeNum")
res <- res %>% mutate(correctCI = lower < truesig & upper > truesig, correctCItest = lower < truesigtest & upper > truesigtest,
length = upper - lower, invalid = n1*n2==0)
res <- res %>% filter(XORLev != 0, XORLev !=3)
knitr::kable(res %>% filter(type=="child", XORLev %in% c(0.25, 1,2), truesig > 0.1*beta) %>% group_by(XORLev, type, depth) %>%
summarize("Median Width, Sample Splitting" = median(length[method=="splitting"], na.rm=TRUE),
"Median Width, Tree-Values" = median(length[method=="Tree-Values"], na.rm=TRUE)))
groupRes <- res %>% filter(type=="child", depth < 4, XORLev %in% c(0.25,1,2)) %>% group_by(method, beta, XORLev, depth) %>% summarize(length=median(length,na.rm=TRUE))
groupRes <- groupRes %>% mutate(XORlev2 = paste0("a=", XORLev),
depth2 = paste0("depth =", depth))
ggplot(data=groupRes, aes(x=beta, y=length, col=method))+ geom_smooth()+facet_grid(cols=vars(XORlev2), rows=vars(depth2))+scale_y_log10()+ylab("Median Length")+xlab(expression(Beta))
max(res$seed)
nullRes <- read.csv("null_res_12-03-20.csv", sep=" ", header=FALSE)
names(nullRes) <- c("cp", "seed", "method", "type", "depth", "pval", "n1", "n2", "sampsig", "NA")
quants_treevalue_split1 <- sort((nullRes %>% filter(depth==1,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split1 <- sort((nullRes %>% filter(depth==1,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node1 <- sort((nullRes %>% filter(depth==1, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node1 <- sort((nullRes %>% filter(depth==1, method=="NaiveZ", type=="child"))$pval)
quants_treevalue_split2 <- sort((nullRes %>% filter(depth==2,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split2 <- sort((nullRes %>% filter(depth==2,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node2 <- sort((nullRes %>% filter(depth==2, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node2 <- sort((nullRes %>% filter(depth==2, method=="NaiveZ", type=="child"))$pval)
quants_treevalue_split3 <- sort((nullRes %>% filter(depth==3,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split3 <- sort((nullRes %>% filter(depth==3,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node3 <- sort((nullRes %>% filter(depth==3, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node3 <- sort((nullRes %>% filter(depth==3, method=="NaiveZ", type=="child"))$pval)
p1 <- ggplot(data=NULL, aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split1))), y=quants_treevalue_split1, col="Tree-Values")) + geom_point()+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split1))), y=quants_pvalue_split1, col="Naive Z")) + geom_abline(slope=1, intercept=0)+xlab("U(0,1) Quantiles") + ylab("Empirical Quantiles")+ggtitle("p-values: Splits")+guides(col=FALSE)+ theme(plot.title = element_text(size = 12),axis.title=element_text(size = 12)) + coord_fixed()+theme_bw()
p2 <- ggplot(data=NULL, aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_node1))), y=quants_treevalue_node1, col="Tree-Values")) + geom_point()+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_node1))), y=quants_pvalue_node1, col="Naive Z")) + geom_abline(slope=1, intercept=0)+xlab("U(0,1) Quantiles") + ylab("Empirical Quantiles")+ggtitle("p-values: Regions")+theme(plot.title = element_text(size = 12),axis.title=element_text(size = 12))+ coord_fixed()+theme_bw()+guides(col=FALSE)#+labs(col="method")
nullResCI <- read.csv("null_res_CI_12-03-20_ALL.csv", sep=",", header=FALSE)
names(nullResCI) <- c("cp", "seed", "method", "type", "depth", "lower", "upper", "n1", "n2", "sampsig")
nullResCI <- nullResCI %>% mutate(correct = lower < 0 & upper > 0) %>% mutate(method = ifelse(method=="Naive Z", "NaiveZ", method)) %>%
mutate(method = ifelse(method=="NaiveZ", "Z", "Tree-Values"),
type = ifelse(type=="split", "Split", "Region"))
nullResCI <- nullResCI %>% mutate(Method2 = paste0(method, ", ", type))
table <- tableGrob(nullResCI %>% group_by(Method2) %>% summarize("Coverage" = round(mean(correct),3)), rows=c("","","",""), cols=c("Method", "Coverage"))
gridExtra::grid.arrange(p1,p2,table, nrow=1,widths=c(2,2,3))
nullRes <- read.csv("null_res_12-03-20.csv", sep=" ", header=FALSE)
names(nullRes) <- c("cp", "seed", "method", "type", "depth", "pval", "n1", "n2", "sampsig", "NA")
quants_treevalue_split1 <- sort((nullRes %>% filter(depth==1,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split1 <- sort((nullRes %>% filter(depth==1,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node1 <- sort((nullRes %>% filter(depth==1, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node1 <- sort((nullRes %>% filter(depth==1, method=="NaiveZ", type=="child"))$pval)
quants_treevalue_split2 <- sort((nullRes %>% filter(depth==2,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split2 <- sort((nullRes %>% filter(depth==2,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node2 <- sort((nullRes %>% filter(depth==2, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node2 <- sort((nullRes %>% filter(depth==2, method=="NaiveZ", type=="child"))$pval)
quants_treevalue_split3 <- sort((nullRes %>% filter(depth==3,method=="Tree-Values", type=="split"))$pval)
quants_pvalue_split3 <- sort((nullRes %>% filter(depth==3,method=="NaiveZ",type=="split"))$pval)
quants_treevalue_node3 <- sort((nullRes %>% filter(depth==3, method=="Tree-Values", type=="child"))$pval)
quants_pvalue_node3 <- sort((nullRes %>% filter(depth==3, method=="NaiveZ", type=="child"))$pval)
p1 <- ggplot(data=NULL, aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split1))), y=quants_treevalue_split1, col="Tree-Values,1")) + geom_point()+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split1))), y=quants_pvalue_split1, col="Naive Z,1")) +
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split2))), y=quants_treevalue_split2, col="Tree-Values,2"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split2))), y=quants_pvalue_split2, col="Naive Z,2"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split3))), y=quants_treevalue_split3, col="Tree-Values,3"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split3))), y=quants_pvalue_split3, col="Naive Z,3"))+
geom_abline(slope=1, intercept=0)+xlab("U(0,1) Quantiles") + ylab("Empirical Quantiles")+ggtitle("p-values: Splits")+guides(col=FALSE)+ theme(plot.title = element_text(size = 12),axis.title=element_text(size = 12)) + coord_fixed()+theme_bw()
p2 <- ggplot(data=NULL, aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_node1))), y=quants_treevalue_node1, col="Tree-Values")) + geom_point()+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_node1))), y=quants_pvalue_node1, col="Naive Z")) + geom_abline(slope=1, intercept=0)+xlab("U(0,1) Quantiles") + ylab("Empirical Quantiles")+ggtitle("p-values: Regions")+theme(plot.title = element_text(size = 12),axis.title=element_text(size = 12))+ coord_fixed()+theme_bw()+guides(col=FALSE)#+labs(col="method")
nullResCI <- read.csv("null_res_CI_12-03-20_ALL.csv", sep=",", header=FALSE)
names(nullResCI) <- c("cp", "seed", "method", "type", "depth", "lower", "upper", "n1", "n2", "sampsig")
nullResCI <- nullResCI %>% mutate(correct = lower < 0 & upper > 0) %>% mutate(method = ifelse(method=="Naive Z", "NaiveZ", method)) %>%
mutate(method = ifelse(method=="NaiveZ", "Z", "Tree-Values"),
type = ifelse(type=="split", "Split", "Region"))
nullResCI <- nullResCI %>% mutate(Method2 = paste0(method, ", ", type))
table <- tableGrob(nullResCI %>% group_by(Method2) %>% summarize("Coverage" = round(mean(correct),3)), rows=c("","","",""), cols=c("Method", "Coverage"))
gridExtra::grid.arrange(p1,p2,table, nrow=1,widths=c(2,2,3))
p1 <- ggplot(data=NULL, aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split1))), y=quants_treevalue_split1, col="Tree-Values,1")) + geom_point()+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split1))), y=quants_pvalue_split1, col="Naive Z,1")) +
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split2))), y=quants_treevalue_split2, col="Tree-Values,2"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split2))), y=quants_pvalue_split2, col="Naive Z,2"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_treevalue_split3))), y=quants_treevalue_split3, col="Tree-Values,3"))+
geom_point(aes(x=qunif(seq(0,1,length.out=length(quants_pvalue_split3))), y=quants_pvalue_split3, col="Naive Z,3"))+
geom_abline(slope=1, intercept=0)+xlab("U(0,1) Quantiles") + ylab("Empirical Quantiles")+ggtitle("p-values: Splits")+guides(col=FALSE)+ theme(plot.title = element_text(size = 12),axis.title=element_text(size = 12)) + coord_fixed()+theme_bw()
p1
shiny::runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
runApp()
runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
runApp('~/DiseaseSimulation')
simulateDisease
runApp('~/DiseaseSimulation')
source("Final_Project.R")
source("Final_Project.R")
setwd("~/DiseaseSimulation")
source("Final_Project.R")
distribution_graph <- initiateNet(input$n.roommates, input$n.workers, input$n.people)
is_party <- TRUE
distribution_graph <- initiateNet(500, 5, 5)
distribution_graph <- initiateNet(500, 5, 5)
distribution_graph <- initiateNet(5, 5,500)
fullResults <- simulateDisease(distribution_graph, 0.05, 365, 0.5, 0.5, is_party=TRUE,
4)
pct.starting.infected <- 0.05
n.workers <- 10
n.roommates <- 3
n.people <- 200
pct.starting.infected <- 0.5
max.time <- 100
pparty <- 0.8
pmask <- 0.1
partyDay <- 4
timeToPlot <- 10
is_party <- FALSE
infected <- sample(
x = c(1, 0),
# people can be infected (T) or susceptible (F)
size = n.people,
# create a vector that is n.people long
replace = T,
# with replacement, so that >1 person can be infected
prob = c(pct.starting.infected, 1 - pct.starting.infected)
)
# Set up a list that tracks infections over time.
# At time step 1, the infections are just the inital infections.
infections <- vector(length = max.time, mode = "list")
infections[[1]] <- infected
# Get the edgelist and add a column that stores whether or not people are roommates
el <-   as_edgelist(distribution_graph) %>%
as.data.frame %>%
set_names(value = c("from", "to"))
for (i in 1:n.roommates) {
el <- el %>% mutate("roommates" = (to == from + n.roommates))
}
# Next, run the loop
for (t in 2:max.time) {
### Every day something happens!!!!!
### First, anyone who has ever been in contact with disease (anyone for who infections[[t]] !=0)
### has their status incremented by a day.
### NOTE: days 1-5 are latent
### days 6-11 are infectious
### days 12+ are recovered
infections[[t]] <- infections[[t - 1]]
infections[[t]][infections[[t]] != 0] <-  infections[[t]][infections[[t]] != 0] + 1
### For every edge in EL, find out if it is at risk of spreading the disease
# This will store edges where the "from" person is susceptible
at_risk_edges_1 <- rep(FALSE, nrow(el))
# This will store edges where the "to" person is susceptible
at_risk_edges_2 <- rep(FALSE, nrow(el))
for (i in 1:nrow(el)) {
person1 <- el[i,1]
person2 <- el[i,2]
### If person 1 is S and person 2 is Infectious
if (infections[[t]][person1] == 0 & (infections[[t]][person2] > 5) & (infections[[t]][person2] <= 11)) {
at_risk_edges_1[i] <- TRUE
}
### If person 2 is S and person 1 is Infectious
if (infections[[t]][person2] == 0 & (infections[[t]][person1] > 5) & (infections[[t]][person1] <= 11)) {
at_risk_edges_2[i] <- TRUE
}
}
### For each edge in at_risk_edges_1, did the disease spread???
### If the people are roomates, it spreads with probability 0.7
### If the people are NOT roommates,spreads with probability 3/7*0.015
### The 3/7 is because there is only a 3/7 probability that you went to work today
infections_roommate <- sample(c(TRUE, FALSE), size=nrow(el), prob=c(0.7, 0.3), replace=TRUE)
infections_coworkers <- sample(c(TRUE, FALSE), size=nrow(el), prob=c(3/7*0.015, 1-3/7*0.015), replace=TRUE)
new_infected_roommates_1 <- at_risk_edges_1 &  el$roommates & infections_roommate
new_infected_roommates_2  <- at_risk_edges_2 &  el$roommates & infections_roommate
new_infected_coworkers_1 <- at_risk_edges_1 & !el$roommates & infections_coworkers
new_infected_coworkers_2  <- at_risk_edges_2 & !el$roommates & infections_coworkers
#### Need to actually make these new people infected!!!
new_infections <- c(el[which(new_infected_roommates_1==TRUE),1],
el[which(new_infected_roommates_2==TRUE),2],
el[which(new_infected_coworkers_1==TRUE),1],
el[which(new_infected_coworkers_2==TRUE),2])
infections[[t]][new_infections] <- 1
#### IF today is the party day, we need to suddenly make a lot of people infected
if(is_party == "TRUE"){
if (t == partyDay) {
infections[[t]] <-
simulateParty(infections[[t]],
pmask,
pparty)
}
}
}
t
infections[[t]][person1]
infections[[t]][person2]
el
head(el)
i
el[i,1]
el[i,2]
indections[[t]]
infections[[t]]
infections[[t]][person2]
infected <- sample(
x = c(1, 0),
# people can be infected (T) or susceptible (F)
size = n.people,
# create a vector that is n.people long
replace = T,
# with replacement, so that >1 person can be infected
prob = c(pct.starting.infected, 1 - pct.starting.infected)
)
# Set up a list that tracks infections over time.
# At time step 1, the infections are just the inital infections.
infections <- vector(length = max.time, mode = "list")
infections[[1]] <- infected
length(infections)
head(infections)
max.time
# Get the edgelist and add a column that stores whether or not people are roommates
el <-   as_edgelist(distribution_graph) %>%
as.data.frame %>%
set_names(value = c("from", "to"))
for (i in 1:n.roommates) {
el <- el %>% mutate("roommates" = (to == from + n.roommates))
}
t=2
### Every day something happens!!!!!
### First, anyone who has ever been in contact with disease (anyone for who infections[[t]] !=0)
### has their status incremented by a day.
### NOTE: days 1-5 are latent
### days 6-11 are infectious
### days 12+ are recovered
infections[[t]] <- infections[[t - 1]]
intections[[t]]
infections[[t]]
length(infections[[t]])
n.people
### Every day something happens!!!!!
### First, anyone who has ever been in contact with disease (anyone for who infections[[t]] !=0)
### has their status incremented by a day.
### NOTE: days 1-5 are latent
### days 6-11 are infectious
### days 12+ are recovered
infections[[t]] <- infections[[t - 1]]
infections[[t]][infections[[t]] != 0] <-  infections[[t]][infections[[t]] != 0] + 1
runApp()
initiateNet <- function(n.roommates, n.workers, n.people) {
distribution <- matrix(0, nrow = n.people, ncol = n.people)
### If 0.5*n.people is the number of people who work, and each person who works
### has n.workers coworkers on average, we can assume that there are around (0.5*n.people)/n.workers
### different workplaces
n.workplaces <- floor(0.5 * n.people / n.workers)
### randomly assign each person to either workplace==0 (not a worker) or a workplace in 1:nworkplaces!
### There is a 50% chance you are not a worker (workplace=0)
### There is a 50% chance that you ARE a worker, and if you are you have an equal chance of being assigned to
### any workplace
workplaces <-
sample(
0:n.workplaces,
size = n.people,
prob = c(0.5, rep(1 / n.workplaces, n.workplaces)),
replace = TRUE
)
## Everyone in a certain workplace is attached to eachother
for (workplace in 1:n.workplaces) {
workers <- which(workplaces == workplace)
distribution[workers, workers] <- 1
}
# Make blocks for roommates where everyone in a house is attached to eachother
for (i in seq(1, n.people - n.roommates, by = n.roommates)) {
distribution[(i:(i + n.roommates - 1)), (i:(i + n.roommates - 1))] <-
1
}
# Subtract 1s from the diagonal of "distibution" because we didn't mean to make each person a
# neighbor of themselves
distribution <- distribution - diag(1, n.people, n.people)
### Everone either has 3 edges or 1 edge
### Workers have 3, nonworkers have 1
distribution_graph <-
graph_from_adjacency_matrix(distribution, "undirected")
return(distribution_graph)
}
runApp()
runApp()
